{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841e660f",
   "metadata": {},
   "source": [
    "Load Some Large Datasets In Streaming Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d957ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# Laion OA convos\n",
    "chat_dataset = load_dataset('OpenAssistant/oasst1', split = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e00ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From LAION notebook on how to work with the dataset\n",
    "import pandas as pd\n",
    "from treelib import Tree\n",
    "\n",
    "chat_df = chat_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443bcc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function from LAION notebook\n",
    "def add_tree_level(df):\n",
    "    \"\"\"helper function to add tree level to a df\"\"\"\n",
    "\n",
    "    # if tree level already exists, return df\n",
    "    if \"tree_level\" in df.columns:\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        tree_level_map = {}\n",
    "\n",
    "        # iterate over rows in df\n",
    "        for i, row in df.iterrows():\n",
    "            message_id = row[\"message_id\"]\n",
    "            parent_id = row[\"parent_id\"]\n",
    "\n",
    "            # if parent_id is None, then it is a root message\n",
    "            if parent_id is None:\n",
    "                tree_level_map[message_id] = 0\n",
    "            # if parent_id is the same as message_tree_id, then it is a direct reply to the root message\n",
    "            elif parent_id == row[\"message_tree_id\"]:\n",
    "                tree_level_map[message_id] = 1\n",
    "            # else just look up the tree level of the parent_id and add 1\n",
    "            else:\n",
    "                tree_level_map[message_id] = tree_level_map[parent_id] + 1\n",
    "\n",
    "        # create a df from the tree_level_map and merge it with the original df\n",
    "        df_tree_level_map = (\n",
    "            pd.DataFrame.from_dict(tree_level_map, orient=\"index\", columns=[\"tree_level\"])\n",
    "            .reset_index()\n",
    "            .rename(columns={\"index\": \"message_id\"})\n",
    "        )\n",
    "\n",
    "        return df.merge(df_tree_level_map, on=\"message_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b122991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random message tree\n",
    "tree_id = chat_df[\"message_tree_id\"].sample(1).values[0]\n",
    "message_tree = chat_df.query(f\"message_tree_id == '{tree_id}'\").sort_values(\"created_date\") # All entries in that tree\n",
    "message_tree = add_tree_level(message_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2951de77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_date</th>\n",
       "      <th>text</th>\n",
       "      <th>role</th>\n",
       "      <th>lang</th>\n",
       "      <th>review_count</th>\n",
       "      <th>review_result</th>\n",
       "      <th>deleted</th>\n",
       "      <th>rank</th>\n",
       "      <th>synthetic</th>\n",
       "      <th>model_name</th>\n",
       "      <th>detoxify</th>\n",
       "      <th>message_tree_id</th>\n",
       "      <th>tree_state</th>\n",
       "      <th>emojis</th>\n",
       "      <th>labels</th>\n",
       "      <th>tree_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b3a054b8-81f9-447e-94a4-0241b785b073</td>\n",
       "      <td>None</td>\n",
       "      <td>9da1e24f-58ff-404c-a71c-827aaef7d73e</td>\n",
       "      <td>2023-02-10T04:03:43.939027+00:00</td>\n",
       "      <td>如果我需要运行一个参数量为176B的语言模型，请问我分别大致需要多少GB显存来进行训练和推断？</td>\n",
       "      <td>prompter</td>\n",
       "      <td>zh</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>b3a054b8-81f9-447e-94a4-0241b785b073</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['+1', '_skip_reply'], 'count': [1, 8]}</td>\n",
       "      <td>{'name': ['spam', 'lang_mismatch', 'pii', 'not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7378c219-30f1-46e2-8ec1-75dcaf134039</td>\n",
       "      <td>b3a054b8-81f9-447e-94a4-0241b785b073</td>\n",
       "      <td>1b1f9abf-a35d-49dc-a71d-49bdfdd79111</td>\n",
       "      <td>2023-02-20T12:39:33.184210+00:00</td>\n",
       "      <td>运行一个参数量为176B的语言模型需要的显存大小取决于所使用的硬件和训练和推断的批处理大小等...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>zh</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>b3a054b8-81f9-447e-94a4-0241b785b073</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['_skip_labeling'], 'count': [1]}</td>\n",
       "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a5ae932-4b7b-499c-a01d-cf14aa0a6b7d</td>\n",
       "      <td>b3a054b8-81f9-447e-94a4-0241b785b073</td>\n",
       "      <td>a7ee8fe3-b13e-4629-b8c0-281fb3035f64</td>\n",
       "      <td>2023-02-21T06:36:00.289792+00:00</td>\n",
       "      <td>对不起呢，我不知道要怎么回答</td>\n",
       "      <td>assistant</td>\n",
       "      <td>zh</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>b3a054b8-81f9-447e-94a4-0241b785b073</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['-1', '_skip_labeling'], 'count': [1...</td>\n",
       "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc069a65-8717-496e-90ce-d5657a8e5449</td>\n",
       "      <td>b3a054b8-81f9-447e-94a4-0241b785b073</td>\n",
       "      <td>0be7fae6-101e-4f37-a4ea-94605b507b8e</td>\n",
       "      <td>2023-03-03T02:15:34.652904+00:00</td>\n",
       "      <td>一般来说，对于大型的语言模型，需要使用高端的GPU硬件来进行训练和推断。具体到需要多少GB的...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>zh</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>b3a054b8-81f9-447e-94a4-0241b785b073</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['+1'], 'count': [1]}</td>\n",
       "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             message_id                             parent_id   \n",
       "0  b3a054b8-81f9-447e-94a4-0241b785b073                                  None  \\\n",
       "1  7378c219-30f1-46e2-8ec1-75dcaf134039  b3a054b8-81f9-447e-94a4-0241b785b073   \n",
       "2  2a5ae932-4b7b-499c-a01d-cf14aa0a6b7d  b3a054b8-81f9-447e-94a4-0241b785b073   \n",
       "3  bc069a65-8717-496e-90ce-d5657a8e5449  b3a054b8-81f9-447e-94a4-0241b785b073   \n",
       "\n",
       "                                user_id                      created_date   \n",
       "0  9da1e24f-58ff-404c-a71c-827aaef7d73e  2023-02-10T04:03:43.939027+00:00  \\\n",
       "1  1b1f9abf-a35d-49dc-a71d-49bdfdd79111  2023-02-20T12:39:33.184210+00:00   \n",
       "2  a7ee8fe3-b13e-4629-b8c0-281fb3035f64  2023-02-21T06:36:00.289792+00:00   \n",
       "3  0be7fae6-101e-4f37-a4ea-94605b507b8e  2023-03-03T02:15:34.652904+00:00   \n",
       "\n",
       "                                                text       role lang   \n",
       "0    如果我需要运行一个参数量为176B的语言模型，请问我分别大致需要多少GB显存来进行训练和推断？   prompter   zh  \\\n",
       "1  运行一个参数量为176B的语言模型需要的显存大小取决于所使用的硬件和训练和推断的批处理大小等...  assistant   zh   \n",
       "2                                     对不起呢，我不知道要怎么回答  assistant   zh   \n",
       "3  一般来说，对于大型的语言模型，需要使用高端的GPU硬件来进行训练和推断。具体到需要多少GB的...  assistant   zh   \n",
       "\n",
       "   review_count review_result  deleted  rank  synthetic model_name detoxify   \n",
       "0             3          True    False   NaN      False       None     None  \\\n",
       "1             3          True    False   0.0      False       None     None   \n",
       "2             3          True    False   2.0      False       None     None   \n",
       "3             3          True    False   1.0      False       None     None   \n",
       "\n",
       "                        message_tree_id        tree_state   \n",
       "0  b3a054b8-81f9-447e-94a4-0241b785b073  ready_for_export  \\\n",
       "1  b3a054b8-81f9-447e-94a4-0241b785b073  ready_for_export   \n",
       "2  b3a054b8-81f9-447e-94a4-0241b785b073  ready_for_export   \n",
       "3  b3a054b8-81f9-447e-94a4-0241b785b073  ready_for_export   \n",
       "\n",
       "                                              emojis   \n",
       "0   {'name': ['+1', '_skip_reply'], 'count': [1, 8]}  \\\n",
       "1         {'name': ['_skip_labeling'], 'count': [1]}   \n",
       "2  {'name': ['-1', '_skip_labeling'], 'count': [1...   \n",
       "3                     {'name': ['+1'], 'count': [1]}   \n",
       "\n",
       "                                              labels  tree_level  \n",
       "0  {'name': ['spam', 'lang_mismatch', 'pii', 'not...           0  \n",
       "1  {'name': ['spam', 'fails_task', 'lang_mismatch...           1  \n",
       "2  {'name': ['spam', 'fails_task', 'lang_mismatch...           1  \n",
       "3  {'name': ['spam', 'fails_task', 'lang_mismatch...           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57669f2a",
   "metadata": {},
   "source": [
    "Some notes:\n",
    "- Message tree has many repeat messages\n",
    "- This is because theres multiple AI responses that are ranked by user\n",
    "- Best way to extract a coherent conversation is:\n",
    "- Randomly pick one of the last prompter messages and follow its parent_id up the tree to create a list of the text associated with those rows\n",
    "- Reverse the list to have a conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b3792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_conversation_from_tree(message_tree):\n",
    "    # Randomly pick one of the last prompter messages\n",
    "    last_prompter_messages = message_tree[message_tree[\"tree_level\"] == message_tree[\"tree_level\"].max()]\n",
    "    selected_message = last_prompter_messages.sample(1)\n",
    "\n",
    "    # Follow its parent_id up the tree to create a list of the text associated with those rows\n",
    "    conversation = []\n",
    "    current_id = selected_message[\"message_id\"].values[0]\n",
    "\n",
    "    while current_id is not None:\n",
    "        current_row = message_tree[message_tree[\"message_id\"] == current_id]\n",
    "        conversation.append(current_row[\"text\"].values[0])\n",
    "        current_id = current_row[\"parent_id\"].values[0]\n",
    "\n",
    "    # Reverse the list to have a conversation\n",
    "    conversation.reverse()\n",
    "\n",
    "    return conversation\n",
    "\n",
    "def sample_conversations(batch_size):\n",
    "    conversations = []\n",
    "    for _ in range(batch_size):\n",
    "        tree_id = chat_df[\"message_tree_id\"].sample(1).values[0]\n",
    "        message_tree = chat_df.query(f\"message_tree_id == '{tree_id}'\").sort_values(\"created_date\")\n",
    "        message_tree = add_tree_level(message_tree)\n",
    "        conversation = sample_conversation_from_tree(message_tree)\n",
    "        conversations.append(conversation)\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6df756",
   "metadata": {},
   "outputs": [],
   "source": [
    "convos = sample_conversations(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df16c163",
   "metadata": {},
   "source": [
    "# SD Pipeline\n",
    "\n",
    "SD pipeline to quickly generate images (this makes it easier to generate random things and experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a64f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7311fdb2a1c24ef78a4776b49eaadb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahbuland\\miniconda3\\envs\\baseml\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shahbuland\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a10eb04f71b46a08c033a0954a31318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835b65670d724659827bec66ab8bc19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e6f26307a34c3abe844875f73f568a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26264806d36e497abaa8fbe3e815d25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/tokenizer_config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd6928dfa0c4204bf766e329d28ba9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/special_tokens_map.json:   0%|          | 0.00/586 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d9071e02f04001ba7c066c12ec1b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder_2/config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f8689f16754590b159f86f652fdab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea89972b22e54faeb019f521d47792f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.fp16.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999557aa63b94136a8af412ce1a95882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32addd24a7a84caf95e9c8709dd7f41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfc1c79956d46a2acbea90c9d023fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d430e7c1694c8a9d59150aaae11a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/tokenizer_config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f8372577e4490aaa7a30d26eb407ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cda068d88cc4d99aec8e0d1bae4ee8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/config.json:   0%|          | 0.00/1.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9d7c802b564c95991a026054e7a663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/607 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588d6d59bac14f5da665a3eb0c9d9987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/5.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30bcf2462a142d789d2bb3bd8e0d13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbb18bacfe449c284e7c3f3c81eee42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b00cb8b132f461eb25a2781e8f343f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import AutoPipelineForText2Image\n",
    "import torch\n",
    "\n",
    "pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "def generate(prompt):\n",
    "    return pipe(prompt=prompt, num_inference_steps = 1, guidance_scale = 0.0).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e12ee8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89e4f9a0ebd4dcea42ed051c4629fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate(\"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06389512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e233827b",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "952da97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from secret import API_KEY\n",
    "openai.api_key = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81691290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatHarness:\n",
    "    def __init__(self, init_prompt = \"You are a helpful assistant\", model = \"gpt-4-1106-preview\"):\n",
    "        self.messages = [{\n",
    "            \"role\" : \"system\", \"content\" : init_prompt\n",
    "        }]\n",
    "        self.model = model\n",
    "    def __call__(self, msg):\n",
    "        self.messages.append({\n",
    "            \"role\" : \"user\", \"content\" : msg\n",
    "        })\n",
    "        res = openai.chat.completions.create(\n",
    "          model=self.model,\n",
    "          messages=self.messages\n",
    "        ).choices[0].message.content\n",
    "        \n",
    "        self.messages.append({\n",
    "            \"role\" : \"assistant\", \"content\" : res\n",
    "        })\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bf7c2eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Paris is a beautiful city filled with incredible attractions. Here are some must-visit places to consider during your trip:\n",
      "\n",
      "1. Eiffel Tower: No trip to Paris is complete without a visit to the iconic Eiffel Tower. You can go up to the top for magnificent views of the city.\n",
      "\n",
      "2. Louvre Museum: Explore the world's largest art museum and admire its vast collection, including the famous Mona Lisa.\n",
      "\n",
      "3. Notre-Dame Cathedral: Marvel at the stunning Gothic architecture of this historic cathedral located on the Île de la Cité.\n",
      "\n",
      "4. Montmartre: Visit this charming neighborhood and explore Sacré-Cœur Basilica, stroll through its charming streets, and enjoy the bohemian atmosphere.\n",
      "\n",
      "5. Champs-Élysées: Walk along this famous avenue, lined with shops, cafes, and landmarks such as the Arc de Triomphe.\n",
      "\n",
      "6. The Seine River: Take a relaxing cruise along the river to see many iconic landmarks like the Louvre, Notre-Dame, and the Eiffel Tower.\n",
      "\n",
      "7. Palace of Versailles: Just outside of Paris, the Palace of Versailles is a must-visit. Explore its opulent halls and stunning gardens.\n",
      "\n",
      "8. Sainte-Chapelle: Admire the exquisite stained glass windows in this medieval Gothic chapel located within the Palais de Justice complex.\n",
      "\n",
      "9. Musée d'Orsay: Discover an impressive collection of impressionist and post-impressionist art in this former railway station turned museum.\n",
      "\n",
      "10. Luxembourg Gardens: Enjoy a leisurely stroll or a picnic in these beautiful public gardens, surrounding the Luxembourg Palace.\n",
      "\n",
      "Remember to check the opening hours and availability of attractions before your visit. Enjoy your time in Paris!\n"
     ]
    }
   ],
   "source": [
    "chat = ChatHarness()\n",
    "print(chat(\"Hello, I'm looking for places to visit in paris during my trip there. Any ideas?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1cea961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes! The park near the Eiffel Tower, called Champ de Mars, is indeed dog-friendly. It's a pleasant green space where you can take your furry friend for a walk or have a picnic. However, do keep in mind that there might be certain areas or sections within the park where dogs might need to be kept on a leash, so it's always a good idea to check the local regulations to ensure a positive experience for everyone.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"Is the park near the eiffel tower dog friendly?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a71497d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be presented with two things: 1. a conversation between a human and an assistant.\n",
      "and 2. An unrelated assortment of pieces of non-text media. You will not be shown the non-text media, but\n",
      "will be given comprehensive textual descriptions of the media (i.e. \n",
      "[[image1] a picture of a golden retreiver playing fetch with his owner who is in a red t shirt. they are both in a park),\n",
      "[[image2] a dining room with a vase in the center. the vase is full of flowers but the flowers are wilting and should be watered,\n",
      "[[audio1] the sound of a dog barking. it is humorous and features a human laughing at the odd barking]])\n",
      "You must insert the media into the conversation as if the conversation brought up the media. Consider this simple\n",
      "example conversation:\n",
      "[\"User: Hello!\", \n",
      "\"Assistant: Hi, how can I help you?\",\n",
      "\"User: I was looking for places to explore in Paris, any ideas?\",\n",
      "\"Assistant: To start, I'd reccomend the Eiffel Tower, the Louvre, and the Notre Dame. Let me know if you need any more suggestions!\",\n",
      "\"User: Thank you! That's a good place to leave off I think\",\n",
      "\"Assistant: You're welcome! Let me know if there's anything else you need my help with\"]\n",
      "You must insert the media in a way that makes sense and naturally adds to the conversation. Only the user can send non-text media.\n",
      "To show that the user sent non-text media, simply insert [image1], [image2] etc. to represent the media. Use the\n",
      "descriptions on the media to dictate how they contribute to the conversation. Try to make inferences about the photo from the description,\n",
      "rather than just stating the description itself. Remember, ONLY THE USER can send non-text media,\n",
      "but the assistant can discuss the media the user sent (and see it). Return a conversation as a list of strings. Here's\n",
      "an example of how the previous media could be added to the conversation:\n",
      "[\"User: Hello!\", \n",
      "\"Assistant: Hi, how can I help you?\",\n",
      "\"User: I was looking for places to explore in Paris, any ideas?\",\n",
      "\"Assistant: To start, I'd reccomend the Eiffel Tower, the Louvre, and the Notre Dame. Let me know if you need any more suggestions!\",\n",
      "\"User: Thank you! I'm actually also travelling there with my dog.\",\n",
      "\"Assistant: Oh I love dogs! Could I see a picture of your dog?\",\n",
      "\"User: Sure! Here you go [image1]\"\n",
      "\"Assistant: Oh wow! A golden retreiver! So cute!!! I like your red shirt. What park was this in?\",\n",
      "\"User: It's actually a local park near my house. He gets super excited whenever I go there\",\n",
      "\"Assistant: That's adorable! If you're taking him to Paris I'm sure he'd love the park near the Eiffen Tower. It's called Champ de Mars and is in fact dog friendly.\",\n",
      "\"User: Oh wow, that's great news! We'll be sure to check it out. This is unrelated but hes making a really weird noise right now. Check this out [audio1]\",\n",
      "\"Assistant: Haha! He sounds so silly. Is there anything else involving your trip you need help with?\",\n",
      "\"User: Not really. I would like some help with home decor though if that's possible.\",\n",
      "\"Assistant: Sure! What do you need help with?\",\n",
      "\"User: Well here's my dining room. Any way to make it more colorful?\",\n",
      "\"Assistant: Oh no! It looks like those flowers are wilting. You should water them as soon as possible.\",\n",
      "\"User: Oops! I'm going to go do that ASAP. Thanks for the help.\",\n",
      "\"Assistant: No problem. Let me know if you need any further help with home decor.\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_synth_prompt = \\\n",
    "\"\"\"You will be presented with two things: 1. a conversation between a human and an assistant.\n",
    "and 2. An unrelated assortment of pieces of non-text media. You will not be shown the non-text media, but\n",
    "will be given comprehensive textual descriptions of the media (i.e. \n",
    "[[image1] a picture of a golden retreiver playing fetch with his owner who is in a red t shirt. they are both in a park),\n",
    "[[image2] a dining room with a vase in the center. the vase is full of flowers but the flowers are wilting and should be watered,\n",
    "[[audio1] the sound of a dog barking. it is humorous and features a human laughing at the odd barking]])\n",
    "You must insert the media into the conversation as if the conversation brought up the media. Consider this simple\n",
    "example conversation:\n",
    "[\"User: Hello!\", \n",
    "\"Assistant: Hi, how can I help you?\",\n",
    "\"User: I was looking for places to explore in Paris, any ideas?\",\n",
    "\"Assistant: To start, I'd reccomend the Eiffel Tower, the Louvre, and the Notre Dame. Let me know if you need any more suggestions!\",\n",
    "\"User: Thank you! That's a good place to leave off I think\",\n",
    "\"Assistant: You're welcome! Let me know if there's anything else you need my help with\"]\n",
    "You must insert the media in a way that makes sense and naturally adds to the conversation. Only the user can send non-text media.\n",
    "To show that the user sent non-text media, simply insert [image1], [image2] etc. to represent the media. Use the\n",
    "descriptions on the media to dictate how they contribute to the conversation. Try to make inferences about the photo from the description,\n",
    "rather than just stating the description itself. Remember, ONLY THE USER can send non-text media,\n",
    "but the assistant can discuss the media the user sent (and see it). Return a conversation as a list of strings. Here's\n",
    "an example of how the previous media could be added to the conversation:\n",
    "[\"User: Hello!\", \n",
    "\"Assistant: Hi, how can I help you?\",\n",
    "\"User: I was looking for places to explore in Paris, any ideas?\",\n",
    "\"Assistant: To start, I'd reccomend the Eiffel Tower, the Louvre, and the Notre Dame. Let me know if you need any more suggestions!\",\n",
    "\"User: Thank you! I'm actually also travelling there with my dog.\",\n",
    "\"Assistant: Oh I love dogs! Could I see a picture of your dog?\",\n",
    "\"User: Sure! Here you go [image1]\"\n",
    "\"Assistant: Oh wow! A golden retreiver! So cute!!! I like your red shirt. What park was this in?\",\n",
    "\"User: It's actually a local park near my house. He gets super excited whenever I go there\",\n",
    "\"Assistant: That's adorable! If you're taking him to Paris I'm sure he'd love the park near the Eiffen Tower. It's called Champ de Mars and is in fact dog friendly.\",\n",
    "\"User: Oh wow, that's great news! We'll be sure to check it out. This is unrelated but hes making a really weird noise right now. Check this out [audio1]\",\n",
    "\"Assistant: Haha! He sounds so silly. Is there anything else involving your trip you need help with?\",\n",
    "\"User: Not really. I would like some help with home decor though if that's possible.\",\n",
    "\"Assistant: Sure! What do you need help with?\",\n",
    "\"User: Well here's my dining room. Any way to make it more colorful?\",\n",
    "\"Assistant: Oh no! It looks like those flowers are wilting. You should water them as soon as possible.\",\n",
    "\"User: Oops! I'm going to go do that ASAP. Thanks for the help.\",\n",
    "\"Assistant: No problem. Let me know if you need any further help with home decor.\"]\n",
    "\"\"\"\n",
    "chat = ChatHarness(data_synth_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a329a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_convo(conversation, media_list):\n",
    "    \"\"\"\n",
    "    Augment a convo by adding media into it. Convo should be list of strings.\n",
    "    Media list should be given as list of tuples with labels for their type \"image\" and then captions describing them\n",
    "    \"\"\"\n",
    "    for i in range(len(conversation)):\n",
    "        if i % 2 == 0:\n",
    "            conversation[i] = \"User: \" + conversation[i]\n",
    "        else:\n",
    "            conversation[i] = \"Assistant: \" + conversation[i]\n",
    "            \n",
    "    res = \"MEDIA INFO:\\n\"\n",
    "    accums = {}\n",
    "    for (label, caption) in media_list:\n",
    "        if label in accums:\n",
    "            accums[label] += 1\n",
    "        else:\n",
    "            accums[label] = 1\n",
    "        res += f\"caption{accums[label]}: {caption}\\n\"\n",
    "    res += f\"CONVERSATION:\\n{conversation}\"\n",
    "    res += \"\\nNow please generate the augmented conversation as a list of strings\"\n",
    "    chat = ChatHarness(data_synth_prompt)\n",
    "    msg = chat(res)\n",
    "    #print(msg)\n",
    "    msg = chat(\"Rejected. Assistant cannot send images. Please try again.\")\n",
    "    print(msg)\n",
    "    #media = msg[msg.find(\"[\")+1:msg.rfind(\"]\")]\n",
    "    #return media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a98571ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"User: If I found a dollar bill, would it be illegal to keep it ?\",\n",
      "\"Assistant: No, it would not be illegal to keep a dollar that you found unattended in public. However, if you \\\"found\\\" a dollar in a tip-jar, on a table at a restaurant, or in someone's home, that would be considered stealing.\",\n",
      "\"User: Should someone who finds lost property be compensated for their efforts in trying to return it to its owner?\",\n",
      "\"Assistant: Morally speaking, it’s nice to offer a reward to someone who went out of their way to return something lost. Legally, there is generally no obligation to compensate someone for returning your property, but some people do anyway as a token of gratitude.\",\n",
      "\"User: Ok, What would be the best way to contact the original owner?\",\n",
      "\"Assistant: If you find a lost item like a dollar bill with no identification, there isn't much you can do to find the original owner. With items that can be traced back to the owner, it's best to use any available contact information, or turn it into local authorities or lost and found locations. Sometimes social media can be helpful in these situations.\",\n",
      "\"User: Speaking of finding things, I recently stumbled upon something quite extraordinary in my back garden. Have a look at this [image1].\",\n",
      "\"Assistant: This is quite the photo—a baby raccoon dressed in an Italian priest robe is definitely not what one would expect to find! It’s quite the curious and amusing image.\",\n",
      "\"User: Yeah, it was a surprising sight for sure. Seems like someone in the neighborhood has an interesting sense of humor. And speaking of creativity, I've been working on some digital art. Here's one of my recent pieces [image2].\",\n",
      "\"Assistant: That's a lovely piece of artwork! The image of a lone reindeer pulling Santa's sleigh adds a unique twist to the classic holiday theme. Your artwork brings a fresh perspective and it's very well-crafted. Keep up the fantastic work!\",\n",
      "\"User: Thanks! I appreciate that. I really do enjoy making art, it's a great way to express myself.\",\n",
      "\"Assistant: Absolutely, it's important to have a creative outlet. Yours seems to not only bring you joy but also produces beautiful results.\"]\n"
     ]
    }
   ],
   "source": [
    "augment_convo(convos[0], [(\"image\", \"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\"), (\"image\", \"a reindeer pulls santas sled by itself, digital artwork\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ee0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
